# Walkthrough {#walkthrough}

```{r, message = FALSE, warning = FALSE, echo = FALSE}
knitr::opts_knit$set(root.dir = fs::dir_create(tempfile()))
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", eval = TRUE)
options(crayon.enabled = FALSE)
```

```{r, include = FALSE, eval = TRUE}
library(fs)
library(targets)
library(tidyverse)
library(withr)
```

```{r, include = FALSE, eval = TRUE}
dir_create("data")
dir_create("R")
write_csv(airquality, "data/raw_data.csv")
withr::with_dir("R", {
  tar_script({
    create_plot <- function(data) {
      ggplot(data) +
        geom_histogram(aes(x = Ozone)) +
        theme_gray(24)
    }
  })
  file_move("_targets.R", "functions.R")
})
tar_script({
  library(targets)
  source("R/functions.R")
  options(crayon.enabled = FALSE)
  options(tidyverse.quiet = TRUE)
  tar_option_set(packages = c("biglm", "tidyverse"))
  list(
    tar_target(
      raw_data_file,
      "data/raw_data.csv",
      format = "file",
      deployment = "main"
    ),
    tar_target(
      raw_data,
      read_csv(raw_data_file, col_types = cols()),
      deployment = "main"
    ),
    tar_target(
      data,
      raw_data %>%
        filter(!is.na(Ozone))
    ),
    tar_target(hist, create_plot(data)),
    tar_target(fit, biglm(Ozone ~ Wind + Temp, data))
  )
})
```

# Walkthrough {#walkthrough}

This chapter walks through a minimal example of a [`targets`](https://github.com/ropensci/targets)-powered data analysis project. The source code is available [here](https://github.com/wlandau/targets-minimal), and it has a free [RStudio Cloud workspace](https://rstudio.cloud/project/1430691) where you can try the code in your web browser. The [documentation website](https://docs.ropensci.org/targets/index.html#examples) links to other examples.

## About this minimal example

The goal of this minimal workflow is to assess the relationship among ozone, wind, and temperature in base R’s `airquality` dataset. We read the data from a file, preprocess it, visualize some of the variables, fit a regression model, and generate an R Markdown report to communicate the results.

## File structure

The file structure of the project looks like this.

```{r, eval = FALSE}
├── _targets.R
├── R/
├──── functions.R
├── data/
└──── raw_data.csv
```

`raw_data.csv` contains the data we want to analyze.

```
Ozone,Solar.R,Wind,Temp,Month,Day
36,118,8.0,72,5,2
12,149,12.6,74,5,3
...
```

`functions.R` contains our custom user-defined functions. (See the [best practices chapter](#practices) for a discussion of function-oriented workflows.)

```{r, eval = FALSE}
# functions.R
create_plot <- function(data) {
  ggplot(data) +
    geom_histogram(aes(x = Ozone)) +
    theme_gray(24)
}
```

Whereas files `raw_data.csv` and `functions.R` are typical user-defined components of a [project-oriented workflow](https://rstats.wtf/project-oriented-workflow.html), `_targets.R` file is special. Every [`targets`](https://github.com/ropensci/targets) workflow needs a file called `_targets.R` in the project's [root directory](https://martinctc.github.io/blog/rstudio-projects-and-working-directories-a-beginner%27s-guide/). Functions [`tar_script()`](https://docs.ropensci.org/targets/reference/tar_script.html) and [`tar_edit()`](https://docs.ropensci.org/targets/reference/tar_edit.html) can help you create one. Ours looks looks like this:

```{r, eval = FALSE}
# _targets.R
library(targets)
source("R/functions.R")
options(tidyverse.quiet = TRUE)
tar_option_set(packages = c("biglm", "tidyverse"))
list(
  tar_target(
    raw_data_file,
    "data/raw_data.csv",
    format = "file"
  ),
  tar_target(
    raw_data,
    read_csv(raw_data_file, col_types = cols())
  ),
  tar_target(
    data,
    raw_data %>%
      filter(!is.na(Ozone))
  ),
  tar_target(hist, create_plot(data)),
  tar_target(fit, biglm(Ozone ~ Wind + Temp, data))
)
```

All `_targets.R` scripts have these requirements.

1. Load the [`targets`](https://github.com/ropensci/targets) package itself. (`_targets.R` scripts created with `tar_script()` automatically insert a `library(targets)` line at the top by default.)
1. Load your custom functions and global objects into the R session. In our case, our only such object is the `create_plot()` function, and we load it into the session by calling `source("R/functions.R")`.
1. Call `tar_option_set()` to set the default settings for all you targets, such as the names of required packages and the data storage format. Individual targets can override these settings.
1. Define individual targets with the `tar_target()` function. Each target is an intermediate step of the workflow. At minimum, a target must have a name and an R expression. This expression runs when the pipeline builds the target, and the return value is saved as a file in the `_targets/objects/` folder. The only targets not stored in `_/targets/objects/` are dynamic files such as `raw_data_file`. Here, `format = "file"` makes `raw_data_file` a dynamic file. That means `targets` watches the data at the file paths returned from the expression (in this case, `"data/raw_data.csv")`.
1. Every `_targets.R` script must end with a list of your `tar_target()` objects. Those objects can be nested, i.e. lists within lists.

## Inspect the pipeline

Before you run the pipeline for real, you should always inspect the manifest and the graph for errors. `tar_manifest()` shows you a data frame information about the targets, and it has functionality to specify the targets and columns returned.

```{r, eval = TRUE}
tar_manifest(fields = "command")
```

There are also graphical displays with `tar_glimpse()`

```{r, eval = TRUE}
tar_glimpse()
```

and `tar_visnetwork()`.

```{r, eval = TRUE}
tar_visnetwork()
```

Both graphing functions above visualize the underlying directed acyclic graph (DAG) and tell you how targets are connected. This DAG is indifferent to the order of targets in your pipeline. You will still get the same graph even if you rearrange them. This is because `targets` uses static code analysis to detect the dependencies of each target, and this process does not depend on target order. For details, visit the [dependency detection section of the best practices guide](https://books.ropensci.org/targets/practice.html#dependencies).

## Run the pipeline

`tar_make()` runs the workflow. It creates a fresh clean external R process, reads `_targets.R` to learn about the pipeline, runs the correct targets in the correct order given by the graph, and saves the necessary data to the `_targets/` data store. ^[In `targets` version 0.3.1.9000 and above, you can set the path of the local data store to something other than `_targets/`. A project-level `_targets.yaml` file keeps track of the path. Functions [`tar_config_set()`](https://docs.ropensci.org/targets/reference/tar_config_set.html) and [`tar_config_get()`](https://docs.ropensci.org/targets/reference/tar_config_get.html) can help.]

```{r, eval = TRUE}
tar_make()
```

The next time you run `tar_make()`, `targets` skips everything that is already up to date, which saves a lot of time in large projects with long runtimes.

```{r, eval = TRUE}
tar_make()
```

You can use `tar_visnetwork()` and `tar_outdated()` to check ahead of time which targets are up to date.

```{r, eval = TRUE}
tar_visnetwork()
```

```{r, eval = TRUE}
tar_outdated()
```

## Changes

The `targets` package notices when you make changes to code and data, and those changes affect which targets rerun and which targets are skipped. Internally, special rules called "cues" decide whether a target reruns. The [`tar_cue()`](https://docs.ropensci.org/targets/reference/tar_cue.html) function lets you suppress some of these cues, and the [`tarchetypes`](https://docs.ropensci.org/tarchetypes/) package supports nuanced [cue factories](https://docs.ropensci.org/tarchetypes/reference/index.html#section-cues) and [target factories](https://docs.ropensci.org/tarchetypes/reference/index.html#section-targets-with-custom-invalidation-rules) to further customize target invalidation behavior. The [`tar_cue()`](https://docs.ropensci.org/targets/reference/tar_cue.html) function documentation [explains cues in detail](https://docs.ropensci.org/targets/reference/tar_cue.html#target-invalidation-rules), as well as [specifics on how `targets` detects changes to upstream dependencies](https://docs.ropensci.org/targets/reference/tar_cue.html#dependency-based-invalidation-and-user-defined-functions).

### Change code

If you change one of your functions, the targets that depend on it will no longer be up to date, and `tar_make()` will rebuild them. For example, let's set the number of bins in our histogram.

```{r, include = FALSE, eval = TRUE}
withr::with_dir("R", {
  tar_script({
    create_plot <- function(data) {
      ggplot(data) +
        geom_histogram(aes(x = Ozone), bins = 11) +
        theme_gray(24)
    }
  })
  file_move("_targets.R", "functions.R")
})
```

```{r, eval = FALSE}
# Edit functions.R.
create_plot <- function(data) {
  ggplot(data) +
    geom_histogram(aes(x = Ozone), bins = 10) + # Set number of bins.
    theme_gray(24)
}
```

`targets` detects the change. `hist` is outdated (as would be any targets downstream of `hist`) and the others are still up to date.

```{r, eval = TRUE}
tar_visnetwork()
```

```{r, eval = TRUE}
tar_outdated()
```

That means `tar_make()` reruns `hist` and nothing else.

```{r, eval = TRUE}
tar_make()
```

We would see similar behavior if we changed the R expressions in any `tar_target()` calls in `_targets.R`.

### Change data

If we change the data file `raw_data.csv`, `targets` notices the change. This is because `raw_data_file` is a dynamic file (i.e. `tar_target(format = "file")`) that returned `"raw_data.csv"`. Let's try it out. Below, let's use only the first 100 rows of the `airquality` dataset.

```{r, eval = TRUE}
write_csv(head(airquality, n = 100), "data/raw_data.csv")
```

Sure enough, `raw_data_file` and everything downstream is out of date, so all our targets are outdated.

```{r, eval = TRUE}
tar_visnetwork()
```

```{r, eval = TRUE}
tar_outdated()
```

```{r, eval = TRUE}
tar_make()
```

## Read your data

`targets` has a convenient functions `tar_read()` to read your data from the `_targets/` data store.

```{r, eval = FALSE}
tar_read(hist)
```

There is also a `tar_load()` function, which supports [`tidyselect`](https://tidyselect.r-lib.org/) verbs like `starts_with()`

```{r, eval = TRUE}
tar_load(starts_with("fit"))
library(biglm)
fit
```

The purpose of `tar_read()` and `tar_load()` is to make exploratory data analysis easy and convenient. Use these functions to verify the correctness of the output from the pipeline and come up with ideas for new targets if needed.

## Read metadata

To read the build progress of your targets while `tar_make()` is running, you can open a new R session and run `tar_progress()`. It reads the spreadsheet in `_targets/meta/progress` and tells you which targets are running, built, errored, or cancelled.

```{r, eval = TRUE}
tar_progress()
```

Likewise, the `tar_meta()` function reads `_targets/meta/meta` and tells you high-level information about the target's settings, data, and results. The `warnings`, `error`, and `traceback` columns give you diagnostic information about targets with problems.

```{r, eval = TRUE, paged.print = FALSE}
tar_meta()
```

The `_targets/meta/meta` spreadsheet file is critically important. Although `targets` can still work properly if files are missing from `_targets/objects`, the pipeline will error out if `_targets/meta/meta` is corrupted. If `tar_meta()` works, the project should be fine.
